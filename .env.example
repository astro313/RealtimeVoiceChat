# Real-Time Voice Chat Configuration
# Copy this file to .env and modify the values as needed

# AWS Whisper Configuration
# Set to "true" to use AWS SageMaker Whisper endpoint instead of local models
USE_AWS_WHISPER=true

# AWS SageMaker Whisper endpoint name (required if USE_AWS_WHISPER=true)
AWS_WHISPER_ENDPOINT=jumpstart-dft-hf-asr-whisper-small-20251024-185556

# AWS Bedrock Configuration (for Claude Haiku LLM)
# AWS profile name to use for authentication (required for AWS services)
AWS_PROFILE_NAME=tszkukle_bindle

# AWS region (required for AWS services)
AWS_REGION=us-east-1

# LLM Backend Configuration
# Choose your LLM backend: bedrock, openai, ollama, lmstudio
LLM_BACKEND=bedrock

# Bedrock model ID (for Bedrock backend)
BEDROCK_MODEL_ID=us.anthropic.claude-3-haiku-20240307-v1:0

# Audio Processing Configuration
# Maximum audio queue size (optional, defaults to 50)
MAX_AUDIO_QUEUE_SIZE=50

# OpenAI API Configuration (if using OpenAI LLM backend)
# OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (if using Ollama backend)
# OLLAMA_BASE_URL=http://127.0.0.1:11434

# LM Studio Configuration (if using LMStudio backend)
# LMSTUDIO_BASE_URL=http://127.0.0.1:1234/v1
